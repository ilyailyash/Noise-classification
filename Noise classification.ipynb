{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import threading\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "FILE_PATTERN = r'*.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize_files(files):\n",
    "    '''Shuffle loaded files'''\n",
    "    for file in files:\n",
    "        file_index = random.randint(0, (len(files) - 1))\n",
    "        yield files[file_index]\n",
    "\n",
    "\n",
    "def find_files(directory, pattern='*.wav'):\n",
    "    '''Recursively finds all files matching the pattern.'''\n",
    "    files = []\n",
    "    fnames = []\n",
    "    for root, dirnames, filenames in os.walk(directory):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            files.append(os.path.join(root, filename))\n",
    "            fnames.append(filename)\n",
    "    return files, fnames\n",
    "\n",
    "def get_category(fname):\n",
    "    '''Parse type from fnamepar'''\n",
    "    return fname.split('/')[-1].split('_')[0]\n",
    "\n",
    "def load_generic_audio(files, sample_rate, amount):\n",
    "    '''Generator that yields audio waveforms from the directory.'''\n",
    "    for it, filename in enumerate(files):\n",
    "        if it == amount:\n",
    "            break\n",
    "        category_id = get_category(filename)\n",
    "        audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "        audio = audio.reshape(-1, 1)\n",
    "        yield audio, filename, category_id\n",
    "\n",
    "# Второе дополнительное задание !!!\n",
    "def trim_silence(audio, threshold, frame_length=512):\n",
    "    '''Removes silence at the beginning and end of a sample.'''\n",
    "    if audio.size < frame_length:\n",
    "        frame_length = audio.size\n",
    "    energy = librosa.feature.rmse(audio, frame_length=frame_length)\n",
    "    frames = np.nonzero(energy > threshold)\n",
    "    indices = librosa.core.frames_to_samples(frames)[1]\n",
    "\n",
    "    # Indices can be an empty array, if the whole audio was background.\n",
    "    return audio[indices[0]:indices[-1]] if indices.size else audio[0:0]\n",
    "\n",
    "\n",
    "\n",
    "class AudioReader(object):\n",
    "    '''Noise audio reader that preprocesses audio files\n",
    "    and add tham in lists'''\n",
    "\n",
    "    def __init__(self,\n",
    "                 audio_dir,\n",
    "                 sample_rate,\n",
    "                 silence_threshold=None,\n",
    "                 sample_size=None,\n",
    "                 load_size=None):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.sample_size = sample_size\n",
    "        self.silence_threshold = silence_threshold\n",
    "        self.load_size = load_size\n",
    "        self.counter = 0\n",
    "        self.time = time.time()\n",
    "\n",
    "        # TODO Find a better way to check this and deal with empty audio.\n",
    "        \n",
    "        self.files, self.fnames = find_files(audio_dir)\n",
    "        if not self.files:\n",
    "            raise ValueError(\"No audio files found in '{}'.\".format(audio_dir))\n",
    "        self.pred_category = np.full(len(self.files), True)\n",
    "        if load_size is not None:\n",
    "            self.data = [0]*load_size\n",
    "            self.id = [0]*load_size\n",
    "        else:    \n",
    "            self.data = [0]*len(self.files)\n",
    "            self.id = [0]*len(self.files)\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        #Read dataset\n",
    "        \n",
    "        iterator = load_generic_audio(self.files, self.sample_rate, self.load_size)\n",
    "        for audio, filename, category_id in iterator:\n",
    "            if self.silence_threshold is not None:\n",
    "                # Remove silence\n",
    "                audio = trim_silence(audio[:, 0], self.silence_threshold)\n",
    "                audio = audio.reshape(-1)\n",
    "                if audio.size == 0:\n",
    "                    self.pred_category[self.counter]=False\n",
    "\n",
    "\n",
    "            self.data[self.counter] = audio\n",
    "            self.id[self.counter] = category_id\n",
    "            self.counter += 1\n",
    "            if self.counter % 400 == 0:\n",
    "                print (time.time() - self.time,self.counter)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.859813451766968 400\n",
      "55.600207805633545 800\n",
      "83.59512448310852 1200\n",
      "109.73975086212158 1600\n",
      "140.96851754188538 2000\n",
      "173.63777685165405 2400\n",
      "204.54908800125122 2800\n",
      "234.78837633132935 3200\n",
      "261.3640329837799 3600\n",
      "290.186096906662 4000\n",
      "320.12978315353394 4400\n",
      "348.68605399131775 4800\n",
      "377.0192017555237 5200\n",
      "408.560928106308 5600\n",
      "438.76555585861206 6000\n",
      "468.65419149398804 6400\n",
      "498.41939902305603 6800\n",
      "529.9439296722412 7200\n",
      "559.9338881969452 7600\n",
      "587.935742855072 8000\n",
      "617.9808473587036 8400\n",
      "646.3717083930969 8800\n",
      "675.6868977546692 9200\n",
      "707.0883450508118 9600\n",
      "735.058333158493 10000\n",
      "770.2843551635742 10400\n",
      "798.5032575130463 10800\n",
      "824.8467507362366 11200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AudioReader at 0x7ff5c4aad278>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dir = './data_v_7_stc/audio' \n",
    "sr = 16000\n",
    "silence_threshold = 7e-4\n",
    "audio_reader = AudioReader(audio_dir,sr,silence_threshold=silence_threshold)\n",
    "audio_reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv('./data_v_7_stc/meta/meta.txt',sep = '\\t')\n",
    "meta.drop(columns=['*','time_start'],inplace=True)\n",
    "to = {'background':0,'bags':1,'door':2,'keyboard':3,'knocking_door':4,'ring':5,'speech':6,'tool':7}\n",
    "fr = {0:'background',1:'bags',2:'door',3:'keyboard',4:'knocking_door',5:'ring',6:'speech',7:'tool'}\n",
    "meta['type'] = meta['type'].map(to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice of silence_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 91) (46086,) 16000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMyv0/wFHsT/ohh3K0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9904dbc278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './data_v_7_stc/audio/background_0019_time_stretch_13.wav' \n",
    "sr = 16000\n",
    "audio, _ = librosa.load(path, sr=sr, mono=True)\n",
    "energy = librosa.feature.rmse(audio, frame_length=512)\n",
    "print (energy.shape, audio.shape, 16000)\n",
    "plt.plot(energy.reshape(-1), 'rx');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7f9906650198>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = find_files('./data_v_7_stc/audio')\n",
    "files[0].split('/')[-1].split('_')[0]\n",
    "def get_type(a):\n",
    "    return a.split('/')[-1].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background_0001.wav 0.00131564\n",
      "background_0001_time_stretch_5.wav 0.00131575\n",
      "background_0004.wav 0.00503398\n",
      "background_0004_time_stretch_1.wav 0.00526163\n",
      "background_0007.wav 0.00769703\n",
      "background_0014.wav 0.0453071\n",
      "background_0014_time_stretch_0.wav 0.0506213\n",
      "background_0042.wav 0.182996\n",
      "background_0042_time_stretch_0.wav 0.189449\n",
      "background_0042_time_stretch_3.wav 0.191987\n",
      "0.191987\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "files = meta[meta['type'] == 0]['fname']\n",
    "rm = np.zeros((len(files),4))\n",
    "for i, file in  enumerate(files):\n",
    "    path = audio_dir + '/' + file\n",
    "    audio, _ = librosa.load(path, sr=sr, mono=True)\n",
    "    energy = librosa.feature.rmse(audio, frame_length=512) \n",
    "    rm[i] = (energy.max(),energy.mean(),energy.std(),energy.min())\n",
    "    if energy.max() > s:\n",
    "        s = energy.max()\n",
    "plt.hist(rm1[:,1], bins=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bags_0001.wav 0.0541228\n",
      "bags_0002.wav 0.24719\n",
      "bags_0033.wav 0.301132\n",
      "bags_0033_time_stretch_3.wav 0.310277\n",
      "bg_0009.wav 0.363868\n",
      "bg_0010.wav 0.522466\n",
      "0.522466\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "files2 = meta[meta['type'] == 1]['fname']\n",
    "rm2 = np.zeros((len(files2),4))\n",
    "for i, file in  enumerate(files2):\n",
    "    path = audio_dir + '/' + file\n",
    "    audio, _ = librosa.load(path, sr=sr, mono=True)\n",
    "    energy = librosa.feature.rmse(audio, frame_length=512) \n",
    "    rm2[i] = (energy.max(),energy.mean(),energy.std(),energy.min())\n",
    "    if energy.max() > s:\n",
    "        s = energy.max()\n",
    "plt.hist(rm2[:,1], bins=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.All feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature(X,sample_rate):\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "#     tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.04747128486633301\n",
      "200 8.350061655044556\n",
      "400 18.696319103240967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.6/site-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 26.1740620136261\n",
      "800 34.89454221725464\n",
      "1000 42.60905718803406\n",
      "1200 51.508061170578\n",
      "1400 59.60135817527771\n",
      "1600 68.4799211025238\n",
      "1800 77.58724093437195\n",
      "2000 86.5558967590332\n",
      "2200 94.39046335220337\n",
      "2400 106.49810528755188\n",
      "2600 114.3032660484314\n",
      "2800 122.66669821739197\n",
      "3000 130.54872155189514\n",
      "3200 137.90328097343445\n",
      "3400 145.56052899360657\n",
      "3600 155.09582376480103\n",
      "3800 161.94757461547852\n",
      "4000 169.0071680545807\n",
      "4200 175.72693157196045\n",
      "4400 185.2217402458191\n",
      "4600 194.28926801681519\n",
      "4800 202.09439063072205\n",
      "5200 215.85578227043152\n",
      "5400 226.63408994674683\n",
      "5600 235.50754809379578\n",
      "5800 243.5435860157013\n",
      "6000 252.72205710411072\n",
      "6200 260.7970190048218\n",
      "6400 268.59473419189453\n",
      "6600 277.7447578907013\n",
      "6800 285.7484998703003\n",
      "7000 293.4403862953186\n",
      "7200 300.8050525188446\n",
      "7400 309.0696964263916\n",
      "7600 319.3274357318878\n",
      "7800 326.24664974212646\n",
      "8000 335.33339738845825\n",
      "8200 344.4191460609436\n",
      "8400 351.74859261512756\n",
      "8600 359.3136749267578\n",
      "8800 366.2633123397827\n",
      "9000 374.2226347923279\n",
      "9200 383.1863532066345\n",
      "9400 391.3719997406006\n",
      "9600 400.4300305843353\n",
      "9800 408.56357073783875\n",
      "10000 418.012571811676\n",
      "10200 425.5972626209259\n",
      "10400 432.690288066864\n",
      "10600 440.8079812526703\n",
      "10800 448.22766518592834\n",
      "11000 454.62348651885986\n",
      "11200 461.9860327243805\n"
     ]
    }
   ],
   "source": [
    "n=len(audio_reader.data)\n",
    "X_train = np.zeros((n,187))\n",
    "start = time.time()\n",
    "for i,arr in enumerate(audio_reader.data):\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    mfccs, chroma, mel, contrast= extract_feature(arr,sr)\n",
    "    X_train[i] = np.hstack([mfccs,chroma,mel,contrast])\n",
    "    if i%200 == 0:\n",
    "        print (i, time.time()-start)\n",
    "meta2 = meta.set_index('fname')\n",
    "files = [0]*len(audio_reader.files)\n",
    "for i,f in enumerate(audio_reader.files):\n",
    "    files[i]=f.split('/')[-1]\n",
    "y_train = np.array(meta2.loc[files]['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('y_train',y_train)\n",
    "np.save('all_features_train',X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.708024740219116 400\n",
      "0 0.041124820709228516\n",
      "300 13.464155197143555\n",
      "600 26.650977849960327\n"
     ]
    }
   ],
   "source": [
    "test_dir='./data_v_7_stc/test'\n",
    "test_reader = AudioReader(test_dir,sr,silence_threshold=silence_threshold)\n",
    "test_reader.read()\n",
    "n=len(test_reader.data)\n",
    "X_full = np.zeros((n,187))\n",
    "start = time.time()\n",
    "for i,arr in enumerate(test_reader.data):\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    mfccs, chroma, mel, contrast= extract_feature(arr,sr)\n",
    "    X_full[i] = np.hstack([mfccs,chroma,mel,contrast])\n",
    "    if i%300 == 0:\n",
    "        print (i, time.time()-start)\n",
    "to = {'background':0,'bags':1,'door':2,'keyboard':3,'knocking':4,'ring':5,'speech':6,'tool':7}\n",
    "T = np.array(test_reader.id)\n",
    "X_test, y_test =X_full[T != 'unknown'],  np.array([to[x] for x in T[T != 'unknown']])\n",
    "X_unknown = X_full[T == 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('T',T)\n",
    "np.save('X_full_test_all_feachers',X_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. mfcc only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5690793991088867\n",
      "300 3.9329147338867188\n",
      "600 7.083946943283081\n",
      "900 10.372597455978394\n",
      "1200 13.718027114868164\n",
      "1500 16.815144300460815\n",
      "1800 20.376691579818726\n",
      "2100 23.496838808059692\n",
      "2400 27.453993797302246\n",
      "2700 30.653042554855347\n",
      "3000 33.998536109924316\n",
      "3300 37.16329765319824\n",
      "3600 40.7586989402771\n",
      "3900 43.51349639892578\n",
      "4200 46.29870820045471\n",
      "4500 50.039504051208496\n",
      "4800 53.13438534736633\n",
      "5100 55.83721947669983\n",
      "5400 59.722572803497314\n",
      "5700 63.05256175994873\n",
      "6000 66.35065150260925\n",
      "6300 69.67478084564209\n",
      "6600 72.96141409873962\n",
      "6900 75.98595523834229\n",
      "7200 78.67790722846985\n",
      "7500 81.79857611656189\n",
      "7800 85.05421876907349\n",
      "8100 88.24935626983643\n",
      "8400 91.26386260986328\n",
      "8700 94.3135130405426\n",
      "9000 97.29276657104492\n",
      "9300 100.64738750457764\n",
      "9600 103.97904968261719\n",
      "9900 107.05752825737\n",
      "10200 110.43324971199036\n",
      "10500 113.2438178062439\n",
      "10800 116.28751158714294\n",
      "11100 119.23323583602905\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-434c20214f30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fname'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "n=len(audio_reader.data)\n",
    "X_train = np.zeros((n,40))\n",
    "start = time.time()\n",
    "for i,arr in enumerate(audio_reader.data):\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    X_train[i]=np.mean(librosa.feature.mfcc(arr,sr,n_mfcc=40).T,axis=0)\n",
    "    if i%500 == 0:\n",
    "        print (i, time.time()-start)\n",
    "meta2 = meta.set_index('fname')\n",
    "files = [0]*len(audio_reader.files)\n",
    "for i,f in enumerate(audio_reader.files):\n",
    "    files[i]=f.split('/')[-1]\n",
    "y_train = np.array(meta2.loc[files]['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24065589904785156 100\n",
      "0.4848320484161377 200\n",
      "0.7339329719543457 300\n",
      "0.9544987678527832 400\n",
      "1.198190450668335 500\n",
      "1.4346206188201904 600\n",
      "0 0.011100292205810547\n",
      "300 4.476659774780273\n",
      "600 8.003519296646118\n"
     ]
    }
   ],
   "source": [
    "test_dir='./data_v_7_stc/test'\n",
    "test_reader = AudioReader(test_dir,sr,silence_threshold=silence_threshold)\n",
    "test_reader.read()\n",
    "n=len(test_reader.data)\n",
    "X_full = np.zeros((n,40))\n",
    "start = time.time()\n",
    "for i,arr in enumerate(test_reader.data):\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    X_full[i]=np.mean(librosa.feature.mfcc(arr,sr,n_mfcc=40).T,axis=0)\n",
    "    if i%300 == 0:\n",
    "        print (i, time.time()-start)\n",
    "to = {'background':0,'bags':1,'door':2,'keyboard':3,'knocking':4,'ring':5,'speech':6,'tool':7}\n",
    "T = np.array(test_reader.id)\n",
    "X_test, y_test =X_full[T != 'unknown'],  np.array([to[x] for x in T[T != 'unknown']])\n",
    "X_unknown = X_full[T == 'unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_model(clf, title):\n",
    "    kfold = KFold(n_splits=3)\n",
    "    cv_res = np.mean(cross_val_score(clf, X_train, y_train, cv=kfold, scoring='neg_log_loss'))\n",
    "    print(title, \"Cross_Entropy_Loss: {0:.3f}\".format(cv_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CE: -0.507\n",
      "Случайный лес CE: -0.266\n",
      "Градиентный бустинг(sklearn) CE: -1.840\n",
      "Градиентный бустинг(xgb) CE: -0.240\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (RandomForestClassifier(max_depth = 10,n_n_estimators = 100,random_state=17), \"Случайный лес\"),\n",
    "    (XGBClassifier(max_depth = 3,n_n_estimators = 1000,random_state=17), \"Градиентный бустинг(xgb)\")\n",
    "]\n",
    "\n",
    "for pair in models:\n",
    "    score_model(*pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=17)\n",
    "kfold = KFold(n_splits=5)\n",
    "parameters = {'n_estimators':[100,500,1000],\n",
    "              'max_depth': [2,3,4],\n",
    "             }\n",
    "grid = GridSearchCV(xgb, parameters, n_jobs=-1, \n",
    "                    cv=kfold, scoring='neg_log_loss', refit=True)\n",
    "grid.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94080338266384778"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb =  XGBClassifier(n_estimators=1000, max_depth=4,n_jobs=-1, random_state=17)\n",
    "xgb.fit(X_train, y_train)\n",
    "pred = xgb.predict_proba(X_test)\n",
    "idx, score = pred.argmax(axis=1), pred.max(axis=1)\n",
    "accuracy_score(y_test,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['door_t_0019.wav' '0.9972068667411804' 'door']\n",
      " ['unknown_0095.wav' '0.7861148715019226' 'knocking_door']\n",
      " ['knocking_door_t_0009.wav' '0.9999330043792725' 'knocking_door']\n",
      " ..., \n",
      " ['door_t_0014.wav' '0.9861352443695068' 'door']\n",
      " ['unknown_0107.wav' '0.4700720012187958' 'knocking_door']\n",
      " ['speech_0051.wav' '0.7889134287834167' 'speech']]\n"
     ]
    }
   ],
   "source": [
    "def write_pred(est, arr,files): \n",
    "    pred = est.predict_proba(arr)\n",
    "    idx, score = pred.argmax(axis=1), pred.max(axis=1)\n",
    "    lables = np.array([fr[x] for x in idx])\n",
    "    res = np.column_stack((files,score,lables))\n",
    "    print (res)\n",
    "    np.savetxt('to_ret_all-1.txt',res,delimiter='\\t',fmt=\"%s\")\n",
    "write_pred(xgb,X_full,test_reader.fnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
